prometheus:
  crdApiGroup: "monitoring.coreos.com"

serviceMonitor:
  enabled: true

  ## PocessExporter ServiceMonitor
  processExporter:
    enabled: true
    ### interval for scrape
    #interval: "10s"
    jobLabel: "process-exporter"
    metricRelabelings: []
    relabelings: []

  ## Ceph ServiceMonitor
  ceph:
    enabled: true
    interval: "30s"
    # Default port is 9283.
    # mon_port:

    mon_hosts:
    - ip: 192.168.97.118

  ## KubeStateMetrics ServiceMonitor
  kubeStateMetrics:
    enabled: true
    interval: "30s"

  ## NodeExporter ServiceMonitor
  nodeExporter:
    enabled: true
    interval: "30s"

  grafana:
    enabled: true
    ### interval for scrape
    #interval: "10s"
    jobLabel: "grafana"
    metricRelabelings: []
    relabelings: []

grafanaDashboard:
  enabled: true
  # namespace installed grafana
  namespace: fed
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
    datasources:
      enabled: true
      label: grafana_datasource
      prometheusAddress: "lma-prometheus-fed-master-prometheus:9090" 

metricbeat:
  enabled: true
  image: docker.elastic.co/beats/metricbeat:7.4.2

  ### metricbeat loglevel
  loglevel: info

  elasticsearch:
    host: "https://elasticsearch-monitoring-es-http:9200"
    username: taco
    password: password
    verification_mode: none

  kibana:
    host: "kibana-dashboard-kb-http:5601"

  ### resources for metricbeat deployment 
  # resources:
  #   requests:
  #     memory: "500Mi"
  #     cpu: "250m"
  #   limits:
  #     memory: "500Mi"
  #     cpu: "500m"  
  
  ### collect metrics from prometheus and save into elasticsearch
  prometheus:
    enabled: true
    hosts: ["192.168.48.202:30018"]

  additionalModules:
    - module: kubernetes
      enabled: true
      metricsets: ["event"]
      period: 10s

